{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4313a8b0-e9b9-4685-a8bf-59bfc049a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tensordict import TensorDict\n",
    "from tensordict.nn import TensorDictModuleBase, set_skip_existing\n",
    "from torchrl.data.replay_buffers import LazyTensorStorage, SamplerWithoutReplacement, TensorDictReplayBuffer\n",
    "from torchrl.objectives import ClipPPOLoss\n",
    "from torchrl.objectives.value import GAE\n",
    "from tqdm import trange\n",
    "from transformers import GPT2Tokenizer, GenerationConfig\n",
    "\n",
    "from data import get_prompt_dataloaders\n",
    "from models.actor_critic import init_actor_critic\n",
    "from models.reward import init_reward_model\n",
    "from models.transformer import init_transformer\n",
    "from utils import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0215d4c5-8909-4609-b7f8-86be8d8b4172",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b985a3d1-996e-47d7-9c10-881a4bd54bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"config/train_rlhf.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36d82041-9809-474d-9523-60008d75c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_transformer(config, inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79c2da18-dbd1-4068-9a93-ba13c6aa471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "515be944-79d1-4194-a2b9-b6649c5fbdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_model = init_reward_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f2d2687-0471-481c-9a01-0599ac05fc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor, critic, critic_head = init_actor_critic(config)\n",
    "critic.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "875af493-f621-4607-b37f-f8fbc5b59ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = ClipPPOLoss(actor, critic_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "011b69ae-e024-4c48-8a55-31004657b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdl, _ = get_prompt_dataloaders(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4730fa-64ef-48f2-8cb0-937dbb9e2457",
   "metadata": {},
   "source": [
    "### computing log probs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc4da871-1096-4aec-ad5b-7eaa6f9d4f0e",
   "metadata": {},
   "source": [
    "```python\n",
    "input_ids = batch.transformer_data.input_ids.clone()\n",
    "# mask out label\n",
    "prompt_rindex = batch.transformer_data.prompt_rindex\n",
    "label_idx = torch.arange(input_ids.shape[1], device=prompt_rindex.device) >= prompt_rindex[:, None]\n",
    "input_ids[label_idx] = 50_256\n",
    "# move padding tokens to left pad\n",
    "input_ids = torch.stack([torch.roll(row, (row == 50_256).sum().item(), 0) for row in input_ids])\n",
    "outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, generation_config=generation_config)\n",
    "\n",
    "scores = torch.stack(outputs.scores, 1)\n",
    "log_probs = scores.max(dim=-1).values - torch.logsumexp(scores, dim=-1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d93944-a439-4b80-8092-357c0b424a9f",
   "metadata": {},
   "source": [
    "### generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b2f60d1-39c6-4235-9d6a-075d4fcb11e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(batch, max_new_tokens=50):\n",
    "    input_ids = batch.transformer_data.input_ids.clone()\n",
    "    # mask out label\n",
    "    prompt_rindex = batch.transformer_data.prompt_rindex\n",
    "    label_idx = torch.arange(input_ids.shape[1], device=prompt_rindex.device) >= prompt_rindex[:, None]\n",
    "    input_ids[label_idx] = 50_256\n",
    "    \n",
    "    # move padding tokens to left pad\n",
    "    input_ids = torch.stack([torch.roll(row, (row == 50_256).sum().item(), 0) for row in input_ids])\n",
    "    \n",
    "    # generate and capture scores\n",
    "    generation_config = GenerationConfig(\n",
    "        output_scores=True,\n",
    "        return_dict_in_generate=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "    )\n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids, attention_mask=(input_ids != 50_256).to(torch.int64), generation_config=generation_config\n",
    "    )\n",
    "    samples = outputs.sequences\n",
    "    generated = torch.ones_like(input_ids) * 50_256\n",
    "    for i, sample in enumerate(samples):\n",
    "        mask = sample != 50_256\n",
    "        generated[i, :mask.sum()] = sample[mask]\n",
    "    scores = torch.stack(outputs.scores, 1)\n",
    "    log_probs = F.pad(\n",
    "        scores.max(dim=-1).values - torch.logsumexp(scores, dim=-1),\n",
    "        (0, max_new_tokens - scores.shape[1]),\n",
    "        value=0,\n",
    "    )\n",
    "    return generated, log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59184cf5-e96b-46df-8095-a0bcd9cae7aa",
   "metadata": {},
   "source": [
    "### rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5f7d508-b7a6-43fa-b652-177155371bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def create_rollout_td(batch, generated, reward_model, log_probs, max_new_tokens=50):\n",
    "    # duplicate the input_ids, revealing one new token each time\n",
    "    # this feels a bit memory inefficient\n",
    "    rollout_generated = torch.stack(\n",
    "        [\n",
    "            torch.stack(\n",
    "                [\n",
    "                    torch.where(torch.arange(row.shape[0], device=generated.device) < rindex + i, row, 50_256) \n",
    "                    for i in range(max_new_tokens + 1)\n",
    "                ]\n",
    "            ) \n",
    "            for rindex, row in zip(batch.transformer_data.prompt_rindex, generated)\n",
    "        ],\n",
    "    )\n",
    "    rollout_attention_mask = (rollout_generated != 50_256).to(torch.int64)\n",
    "    done_idx = torch.minimum(\n",
    "        (generated != 50_256).sum(dim=-1) - batch.transformer_data.prompt_rindex, torch.tensor(max_new_tokens)\n",
    "    )\n",
    "    done = (\n",
    "        torch.arange(max_new_tokens, device=generated.device) == done_idx[:, None]\n",
    "    ).unsqueeze(-1)\n",
    "    _, end_scores = reward_model(\n",
    "        input_ids=rollout_generated[:, -1], attention_mask=rollout_attention_mask[:, -1]\n",
    "    )\n",
    "    _, end_scores_labels = reward_model(\n",
    "        batch.transformer_data.input_ids, batch.transformer_data.attention_mask\n",
    "    )\n",
    "    reward = done * (end_scores - end_scores_labels)[:, None, None]\n",
    "    action_idx = torch.stack(\n",
    "        [\n",
    "            torch.arange(i, i + max_new_tokens, device=generated.device)\n",
    "            for i in batch.transformer_data.prompt_rindex\n",
    "        ]\n",
    "    )\n",
    "    action = generated[\n",
    "        torch.arange(generated.shape[0], device=generated.device)[:, None], \n",
    "        action_idx,\n",
    "    ]\n",
    "    #TODO: KL\n",
    "    td = {\n",
    "        \"action\": action,\n",
    "        \"input_ids\": rollout_generated[:, :-1].clone(),\n",
    "        \"attention_mask\": rollout_attention_mask[:, :-1].clone(),\n",
    "        \"sample_log_prob\": log_probs,\n",
    "        \"next\": {\n",
    "            \"input_ids\": rollout_generated[:, 1:].clone(),\n",
    "            \"attention_mask\": rollout_attention_mask[:, 1:].clone(),\n",
    "            \"done\": done,\n",
    "            \"reward\": reward,\n",
    "        }\n",
    "    }\n",
    "    return TensorDict(td, batch_size=done.shape[:2], device=generated.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8675131b-845d-4781-a6c7-b63227bcc1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(tdl)\n",
    "generated, log_probs = generate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e6572390-6434-47eb-accb-f401516d8a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = create_rollout_td(batch, generated, reward_model, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b6e87c07-5bd9-4251-8b4e-b24d3476fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VmapCritic(TensorDictModuleBase):\n",
    "    def __init__(self, critic):\n",
    "        super().__init__()\n",
    "        self.in_keys = critic.in_keys\n",
    "        self.out_keys = critic.out_keys\n",
    "        self.module = critic\n",
    "\n",
    "    def forward(self, tensordict):\n",
    "        ndim = tensordict.ndim\n",
    "        training = self.module.training\n",
    "        self.module.eval()\n",
    "        td = torch.vmap(self.module, (ndim - 1,))(tensordict)\n",
    "        self.module.train(training)\n",
    "        # vmap sends this dim to the beginning so we need to send it back where it belongs\n",
    "        td = td.permute(*range(1, ndim), 0)\n",
    "        return tensordict.update(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8130411b-76f3-41ce-9a79-56d1973f5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_fn = GAE(\n",
    "    value_network=VmapCritic(critic), gamma=0.99, lmbda=0.95, average_gae=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c02ebe-5cd8-45a2-9501-db4d4f9876d6",
   "metadata": {},
   "source": [
    "Typical PPO loop should look something like\n",
    "\n",
    "```python\n",
    "for data in collector:\n",
    "    for epoch in range(n_epochs):\n",
    "        advantage(data)\n",
    "        replay_buffer.extend(data)\n",
    "        for batch in replay_buffer:\n",
    "            loss = ppo_loss(batch)  \n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bad55c41-5c1d-4f49-8906-7b186a568aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = config[\"learning_rate\"]\n",
    "wd = config[\"weight_decay\"]\n",
    "beta1 = config[\"beta1\"]\n",
    "beta2 = config[\"beta2\"]\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    loss_fn.parameters(), lr=lr, weight_decay=wd, betas=(beta1, beta2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6f53c97a-515f-412b-b001-872950f9fa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "done = td[\"next\", \"done\"]\n",
    "mask = torch.zeros_like(done)\n",
    "mask[..., 1:, :] = done[..., :-1, : ] # shift by one\n",
    "mask = ~mask.cumsum(-2).bool().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4a1850-9827-4df3-9c2b-38692312ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb = TensorDictReplayBuffer(\n",
    "    storage=LazyTensorStorage(config[\"episode_length\"] * config[\"batch_size\"]),\n",
    "    batch_size=config[\"ppo_batch_size\"],\n",
    "    sampler=SamplerWithoutReplacement(),\n",
    ")\n",
    "losses = []\n",
    "\n",
    "for _ in trange(min(5, config[\"max_iters\"])):\n",
    "    # form batch\n",
    "    batch = next(tdl)\n",
    "    generated = generate(batch)\n",
    "    td = create_rollout_td(batch, generated, reward_model)\n",
    "    with torch.no_grad():\n",
    "        adv_fn(td)\n",
    "    rb.extend(td.reshape(-1))\n",
    "\n",
    "    for j, batch in enumerate(rb):\n",
    "        loss_vals = loss_fn(batch.to(config[\"device\"]))\n",
    "\n",
    "        loss_val = sum(\n",
    "            value for key, value in loss_vals.items() if key.startswith(\"loss\")\n",
    "        )\n",
    "        loss_val.backward()\n",
    "        losses.append(loss_val.detach().cpu())\n",
    "        gn = torch.nn.utils.clip_grad_norm_(loss_fn.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8114bc7-e49d-4b44-b20c-85030851b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01284ac-5e29-43bf-8efe-da04133129dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(tdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a1dfa7-8d52-4ce2-b03d-f3c587f3250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f055fc15-e551-44eb-8c3d-93eef09df4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_model(batch.transformer_data.input_ids, batch.transformer_data.attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f5d451-4a77-4ddd-96fb-307a13ece666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
